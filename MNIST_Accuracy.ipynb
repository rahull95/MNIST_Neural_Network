{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQ0dvure8dz1"
   },
   "source": [
    "# PART 1: Warm-Up - Running baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MiUXJbKaOeSg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dNcb86AIOmwp",
    "outputId": "8fcf7494-e9ce-43f0-f764-c26537f75107"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, LSTM, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import math\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpJn2Of6PhDY"
   },
   "outputs": [],
   "source": [
    "np.random.seed(19)\n",
    "random.seed(100)\n",
    "tf.random.set_seed(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxvJ6kBHPk_9"
   },
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NexHHkEFPnG7"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4WND0uZPrWl"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMH7a2kSPtVx"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "k_3gQO94PwJW",
    "outputId": "320430bd-dc29-4a95-e1a7-4f8a7ca5fea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.2422 - accuracy: 0.9252 - val_loss: 0.1144 - val_accuracy: 0.9637\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1021 - accuracy: 0.9693 - val_loss: 0.0900 - val_accuracy: 0.9737\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0744 - accuracy: 0.9767 - val_loss: 0.0780 - val_accuracy: 0.9779\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0613 - accuracy: 0.9819 - val_loss: 0.0705 - val_accuracy: 0.9807\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 0.0741 - val_accuracy: 0.9808\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0432 - accuracy: 0.9870 - val_loss: 0.0731 - val_accuracy: 0.9820\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0693 - val_accuracy: 0.9827\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 0.0844 - val_accuracy: 0.9810\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.0773 - val_accuracy: 0.9834\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.0982 - val_accuracy: 0.9829\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0247 - accuracy: 0.9930 - val_loss: 0.1013 - val_accuracy: 0.9824\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.1145 - val_accuracy: 0.9818\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.1073 - val_accuracy: 0.9829\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.1150 - val_accuracy: 0.9839\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.1020 - val_accuracy: 0.9830\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.1159 - val_accuracy: 0.9848\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.1186 - val_accuracy: 0.9826\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.1269 - val_accuracy: 0.9835\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.1256 - val_accuracy: 0.9822\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.1276 - val_accuracy: 0.9820\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.1172 - val_accuracy: 0.9851\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.1423 - val_accuracy: 0.9825\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.1275 - val_accuracy: 0.9841\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.1354 - val_accuracy: 0.9840\n",
      "Test loss: 0.13543180533591484\n",
      "Test accuracy: 0.984000027179718\n"
     ]
    }
   ],
   "source": [
    "#Baseline model for MNIST - running for 25 epochs\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.optimizer.lr = 0.01\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Xh0cwD_RS0o1",
    "outputId": "057c8168-eb4d-418b-a142-aead38d0a207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850999712944031"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After 25 epochs\n",
    "max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlUmzEQoBamj"
   },
   "source": [
    "### After 25 epochs, we get a maximum val_accuracy of **98.5%**. At this point the accuracy doesn't show significant improvement, hence we might need to modify the layers to increase the performance on the dataset, and it'll only overfit if we increase the epochs without changing model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZCjUXw-9Deu"
   },
   "source": [
    "# PART 2: Increasing accuracy by modifying network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bZWHBSl39QWv",
    "outputId": "cb8dc514-9f25-430a-c0d4-8b1852949c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 221,226\n",
      "Trainable params: 221,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.2343 - accuracy: 0.9265 - val_loss: 0.0563 - val_accuracy: 0.9826\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0695 - accuracy: 0.9786 - val_loss: 0.0376 - val_accuracy: 0.9877\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0383 - val_accuracy: 0.9870\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.0256 - val_accuracy: 0.9901\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0277 - val_accuracy: 0.9892\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.0249 - val_accuracy: 0.9916\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0219 - val_accuracy: 0.9921\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0279 - val_accuracy: 0.9905\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0228 - val_accuracy: 0.9925\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0240 - val_accuracy: 0.9925\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0220 - val_accuracy: 0.9930\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0247 - val_accuracy: 0.9927\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0248 - val_accuracy: 0.9931\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 107s 2ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0265 - val_accuracy: 0.9925\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0283 - val_accuracy: 0.9924\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0255 - val_accuracy: 0.9923\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0251 - val_accuracy: 0.9932\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0253 - val_accuracy: 0.9926\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0257 - val_accuracy: 0.9921\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0234 - val_accuracy: 0.9929\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0271 - val_accuracy: 0.9930\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0258 - val_accuracy: 0.9933\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0286 - val_accuracy: 0.9938\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0285 - val_accuracy: 0.9933\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0279 - val_accuracy: 0.9934\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0290 - val_accuracy: 0.9925\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0272 - val_accuracy: 0.9929\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0304 - val_accuracy: 0.9924\n",
      "Test loss: 0.030443396661868762\n",
      "Test accuracy: 0.9923999905586243\n"
     ]
    }
   ],
   "source": [
    "#Beating test accuracy for MNIST\n",
    "\n",
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same',input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ub5PTR-Mmx6k"
   },
   "source": [
    "### After experimenting with different setups, the final model I've built has a validation accuracy of close to **99.2%** after 30 epochs. Beyond this number, there isn't much increase in val_accuracy while the train_accuracy increases, suggesting overfitting.\n",
    "\n",
    "**The final model has the following layers:**\n",
    "\n",
    "\n",
    "*   Conv2D with 64 filters\n",
    "*   MaxPool with pool size (2,2)\n",
    "*   Dropout (0.25)\n",
    "*   Conv2D with 32 filters\n",
    "*   MaxPool with pool size (2,2)\n",
    "*   Dropout (0.25)\n",
    "*   Flatten this input onto a dense layer\n",
    "*   Dense layer with 128 units\n",
    "*   Softmax output with 10 classes\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mini Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
